<html lang="en">
<%- include("./partials/head.ejs") %>

<body>
  <%- include("./partials/nav.ejs") %>
    <div class="container">
      <h1 class="paper-title text-center">Blockchains and Cryptographic Hashes to Regulate the Proliferation of Deepfakes</h1>
      <p class="author text-center">By Ahmed Hussain and Zachary Yahn</p>
  
      <section>
        <h2 class="section-title">Introduction</h2>
        <section>
          <p>Deep learning, a branch of machine learning based on artificial neural network architectures, has been applied to many complex problems in the modern age. Ranging from robotics to computer vision to data analytics, applications of deep learning have typically resulted in significant advances in both performance and speed. However, advances in the field of deep learning have also been used to threaten privacy, democracy, and security. An example of these recently emerging deep learning applications is the "deepfake." Deepfake algorithms can create artificial images, video, and audio which are almost impossible for humans to differentiate from real media. This presents threats to our technological lifestyles and media-dominated culture through the possibility of malicious intervention and cybersecurity risks. Therefore, in this whitepaper we propose an end-to-end blockchain solution which can automatically detect and assess the integrity of digital media using video hash functions. By using both technical and conceptual details and covering modern examples, we present an introduction to deepfakes, an overview of generative adversarial networks, our proposal for a detection framework, and a summary of potential future research. </p>
        </section>
      </section>
  
      <section>
        <h2 class="section-title">Deepfakes and Cyberwarfare</h2>
        <section>
          <h4>Overview</h4>
          <p>A deepfake1, the portmanteau of "deep neural network" and "fake", is a form of media, typically in video or audio form, which modifies a subject’s face, body, or voice digitally using deep learning models to appear to be someone/something else. In the past, deepfakes have been used to spread malicious or false information online through social media or other mass forms of communication to interfere with public discourse. There is also a distinction between a deepfake, which uses deep neural networks (DNNs) to forge the media, and a "shallowfake" or "cheapfake", which aims to achieve the same end result using standard video editing or programming techniques.
            Deepfakes are built using two machine learning models, specifically deep neural networks, which compete with each other to produce high quality media. This machine learning technique of competing neural networks is called a generative adversarial network2, or GAN.</p>
        </section>
  
        <section>
          <h4>Ethics and Controversy</h4>
          <p>For better or worse, deepfakes have found their place in news headlines and social media posts. One popular example is the portrayal of recently passed actors and actresses on the big screen using algorithmically recreated faces3. Deepfakes have also caught the attention of everyday people through mobile applications like FaceApp4, which allow a user take a picture of a face and morph it with different features. Video deepfakes are even more common than initially thought, as companies like Apple and Snapchat implement advanced camera filters that can be used to modify faces and objects in real time. In terms of audio, one
            startup, CereProc5, was able to restore the voice of Roger Ebert, who suffered from ALS, and use it to say anything in real time. This synthetic audio technology is only improving, giving many people a voice of their own for the first time in their lives.
            However, deepfake technology has also been used to great effect by malicious actors, such as convincing a UK-based energy firm to transfer funds to a fraudulent account. This was accomplished by creating an audio deepfake6 of the CEO’s voice and calling company executives. Others have attempted similar approaches, employing the same technology for spam calls and fake audio messages. While a trained eye or ear can sometimes spot a fake, the technology could become advanced enough to fool most people.
            </p>
        </section>
  
        <section>
          <h4>Target Issue</h4>
          <p>Perhaps the most dangerous application of deepfakes is the widespread dissemination of fake news and distrust in the media, sometimes dubbed as "5th generation cyberwarfare7" due to the large scale, multi- vector attacks designed to infect many components of an information infrastructure. As deepfakes work best with ample training data, any politician, celebrity, or public figure with videos online could potentially be targeted by a deepfake. A prominent example of a deepfake was Jordan Peele’s demonstration of the technology when he used GANs and voice acting to create an entirely fake video of President Barack Obama8. Similarly, an example of a shallowfake in popular media is Nancy Pelosi’s speech at the CAP Ideas conference in 20199; the original video of the speech was taken and altered using typical editing techniques to slur her words and reduce her speech coherence.
            It is difficult to know when a viral video is real, as the vast amounts of potential training data made available with every public appearance makes these individuals vulnerable targets for powerful models. In one significant example of public distrust due to this technology, the government of Gabon was overthrown in a coup after the sitting president addressed the country10. Broadcast as a live video to the entire nation, the address was perceived as a deepfake, partially contributing to an uprising. While several sources have confirmed that the video was not a fake (the president had recently suffered a stroke that made his facial features seem artificial), the possibility was enough to spark resentment for the populace.
            As personal computers become increasingly powerful, the danger of deepfakes only grows. Anyone with an internet connection and knowledge of deep learning can produce a semi-convincing deepfake of politicians and public figures, with the potential to sow mass confusion. Social media spreads information - true or false - at a breathtaking pace perfect for fake media. Researchers have already developed several methods for combatting deepfakes, though there is still room for improvement. As it becomes ever harder to know which media to trust, there is a demand for new technologies which restore the public’s confidence in the information they consume.</p>
        </section>
      </section>
    </div>

    <!-- Local JS -->
    <script src="/web.js"></script> 
    <!-- Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

  
  <%- include("./partials/footer.ejs") %>
</body>
</html>
